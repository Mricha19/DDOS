{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30bbfcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as pn\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48289a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv('preprocessed_test_4_new.csv')\n",
    "testdata = pd.read_csv('preprocessed_train_4_new.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6da85256",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = traindata.iloc[0:,1:71]# 71 columns of data frame with all rows\n",
    "Y = traindata.iloc[0:,71] \n",
    "T = testdata.iloc[0:,1:71]\n",
    "C = testdata.iloc[0:,71]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ca2ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83a46655",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pn.array(trainX)\n",
    "trainlabel = pn.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71f0f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = pn.array(testT)\n",
    "testlabel = pn.array(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8985fbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Random Forest binary----------------------------\n",
      "Accuracy: \n",
      "1.000\n",
      "FPR: \n",
      "1.000\n",
      "TPR: \n",
      "1.000\n",
      "Confusion matrix: \n",
      "[[676801      0]\n",
      " [     9 162050]]\n",
      "Classification report for %s RandomForestClassifier()\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    676801\n",
      "           1       1.00      1.00      1.00    162059\n",
      "\n",
      "    accuracy                           1.00    838860\n",
      "   macro avg       1.00      1.00      1.00    838860\n",
      "weighted avg       1.00      1.00      1.00    838860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------Random Forest binary----------------------------\")\n",
    "#create the model with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model = model.fit(traindata, trainlabel)\n",
    "\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "## Actual class predictions\n",
    "predicted = model.predict(testdata)\n",
    "pn.savetxt('predictedRF.txt', predicted, fmt='%01d')\n",
    "# summarize the fit of the model\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "tpr = float(cm[0][0])/pn.sum(cm[0])\n",
    "fpr = float(cm[1][1])/pn.sum(cm[1])\n",
    "print(\"Accuracy: \")\n",
    "print(\"%.3f\" %accuracy)\n",
    "\n",
    "\n",
    "print(\"FPR: \")\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"TPR: \")\n",
    "print(\"%.3f\" %tpr)\n",
    "\n",
    "print (\"Confusion matrix: \")\n",
    "print (metrics.confusion_matrix(expected, predicted))\n",
    "# performance\n",
    "print (\"Classification report for %s\",  model)\n",
    "print (\"\\n\")\n",
    "print (metrics.classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac384b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
